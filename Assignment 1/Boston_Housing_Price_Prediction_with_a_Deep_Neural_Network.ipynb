{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YOTzZhdR9zZt"
   },
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_F2vhnLJ3lm6"
   },
   "outputs": [],
   "source": [
    "# Data analysis and visualization\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "# Preprocessing and evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YhqBbskr-iag"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ILfTB4Ow3OAU",
    "outputId": "96cf0938-0070-41b5-d59d-d32f2fda7e6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
      "57344/57026 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train , y_train), (X_test , y_test) = tf.keras.datasets.boston_housing.load_data(\n",
    "                                            path = 'boston_housing_npz',\n",
    "                                            test_split = 0.2,\n",
    "                                            seed = 42\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hHPrTJsyHKSO"
   },
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iFxpm9uu-mcs"
   },
   "source": [
    "## Initial Observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lmgYsStF3vyi",
    "outputId": "d9d7c9ad-7e0a-4d0e-9c71-e20775ea9dc5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((404, 13), numpy.ndarray),\n",
       " ((102, 13), numpy.ndarray),\n",
       " ((404,), numpy.ndarray),\n",
       " ((102,), numpy.ndarray))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the data shape and type\n",
    "(X_train.shape, type(X_train)), (X_test.shape, type(X_test)), (y_train.shape, type(y_train)), (y_test.shape, type(y_test)),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "-QVH6Dcl37Dl",
    "outputId": "860b6d19-12bf-4db1-a0bb-f579a0e671f0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.09178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.510</td>\n",
       "      <td>6.416</td>\n",
       "      <td>84.1</td>\n",
       "      <td>2.6463</td>\n",
       "      <td>5.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>16.6</td>\n",
       "      <td>395.50</td>\n",
       "      <td>9.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05644</td>\n",
       "      <td>40.0</td>\n",
       "      <td>6.41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.447</td>\n",
       "      <td>6.758</td>\n",
       "      <td>32.9</td>\n",
       "      <td>4.0776</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>17.6</td>\n",
       "      <td>396.90</td>\n",
       "      <td>3.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.10574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.609</td>\n",
       "      <td>5.983</td>\n",
       "      <td>98.8</td>\n",
       "      <td>1.8681</td>\n",
       "      <td>4.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>390.11</td>\n",
       "      <td>18.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.09164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.413</td>\n",
       "      <td>6.065</td>\n",
       "      <td>7.8</td>\n",
       "      <td>5.2873</td>\n",
       "      <td>4.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>390.91</td>\n",
       "      <td>5.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.09017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.713</td>\n",
       "      <td>6.297</td>\n",
       "      <td>91.8</td>\n",
       "      <td>2.3682</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>385.09</td>\n",
       "      <td>17.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.10153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.437</td>\n",
       "      <td>6.279</td>\n",
       "      <td>74.5</td>\n",
       "      <td>4.0522</td>\n",
       "      <td>5.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>373.66</td>\n",
       "      <td>11.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.31827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.544</td>\n",
       "      <td>5.914</td>\n",
       "      <td>83.2</td>\n",
       "      <td>3.9986</td>\n",
       "      <td>4.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>390.70</td>\n",
       "      <td>18.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.29090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.624</td>\n",
       "      <td>6.174</td>\n",
       "      <td>93.6</td>\n",
       "      <td>1.6119</td>\n",
       "      <td>4.0</td>\n",
       "      <td>437.0</td>\n",
       "      <td>21.2</td>\n",
       "      <td>388.08</td>\n",
       "      <td>24.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.03841</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.532</td>\n",
       "      <td>6.229</td>\n",
       "      <td>90.7</td>\n",
       "      <td>3.0993</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>395.33</td>\n",
       "      <td>12.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.22438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>6.027</td>\n",
       "      <td>79.7</td>\n",
       "      <td>2.4982</td>\n",
       "      <td>6.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>14.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1      2    3      4      5     6       7     8      9     10  \\\n",
       "0  0.09178   0.0   4.05  0.0  0.510  6.416  84.1  2.6463   5.0  296.0  16.6   \n",
       "1  0.05644  40.0   6.41  1.0  0.447  6.758  32.9  4.0776   4.0  254.0  17.6   \n",
       "2  0.10574   0.0  27.74  0.0  0.609  5.983  98.8  1.8681   4.0  711.0  20.1   \n",
       "3  0.09164   0.0  10.81  0.0  0.413  6.065   7.8  5.2873   4.0  305.0  19.2   \n",
       "4  5.09017   0.0  18.10  0.0  0.713  6.297  91.8  2.3682  24.0  666.0  20.2   \n",
       "5  0.10153   0.0  12.83  0.0  0.437  6.279  74.5  4.0522   5.0  398.0  18.7   \n",
       "6  0.31827   0.0   9.90  0.0  0.544  5.914  83.2  3.9986   4.0  304.0  18.4   \n",
       "7  0.29090   0.0  21.89  0.0  0.624  6.174  93.6  1.6119   4.0  437.0  21.2   \n",
       "8  4.03841   0.0  18.10  0.0  0.532  6.229  90.7  3.0993  24.0  666.0  20.2   \n",
       "9  0.22438   0.0   9.69  0.0  0.585  6.027  79.7  2.4982   6.0  391.0  19.2   \n",
       "\n",
       "       11     12  \n",
       "0  395.50   9.04  \n",
       "1  396.90   3.53  \n",
       "2  390.11  18.07  \n",
       "3  390.91   5.52  \n",
       "4  385.09  17.27  \n",
       "5  373.66  11.97  \n",
       "6  390.70  18.33  \n",
       "7  388.08  24.16  \n",
       "8  395.33  12.87  \n",
       "9  396.90  14.33  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting Data to DataFrame \n",
    "X_train_df = pd.DataFrame(X_train)\n",
    "y_train_df = pd.DataFrame(y_train)\n",
    "\n",
    "# Preview the training data\n",
    "X_train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NtocpgHS6zUg",
    "outputId": "874e6070-2117-49b5-968e-44f980f9219e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 404 entries, 0 to 403\n",
      "Data columns (total 13 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       404 non-null    float64\n",
      " 1   1       404 non-null    float64\n",
      " 2   2       404 non-null    float64\n",
      " 3   3       404 non-null    float64\n",
      " 4   4       404 non-null    float64\n",
      " 5   5       404 non-null    float64\n",
      " 6   6       404 non-null    float64\n",
      " 7   7       404 non-null    float64\n",
      " 8   8       404 non-null    float64\n",
      " 9   9       404 non-null    float64\n",
      " 10  10      404 non-null    float64\n",
      " 11  11      404 non-null    float64\n",
      " 12  12      404 non-null    float64\n",
      "dtypes: float64(13)\n",
      "memory usage: 41.2 KB\n",
      "________________________________________\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 404 entries, 0 to 403\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       404 non-null    float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 3.3 KB\n"
     ]
    }
   ],
   "source": [
    "# View summary of datasets\n",
    "X_train_df.info()\n",
    "print('_'*40)\n",
    "y_train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "id": "CeeFStx68vMP",
    "outputId": "887bb519-8460-4c38-f52a-e7c65e66a221"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.789989</td>\n",
       "      <td>11.568069</td>\n",
       "      <td>11.214059</td>\n",
       "      <td>0.069307</td>\n",
       "      <td>0.554524</td>\n",
       "      <td>6.284824</td>\n",
       "      <td>69.119307</td>\n",
       "      <td>3.792258</td>\n",
       "      <td>9.660891</td>\n",
       "      <td>408.960396</td>\n",
       "      <td>18.481931</td>\n",
       "      <td>356.293020</td>\n",
       "      <td>12.825520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.132761</td>\n",
       "      <td>24.269648</td>\n",
       "      <td>6.925462</td>\n",
       "      <td>0.254290</td>\n",
       "      <td>0.116408</td>\n",
       "      <td>0.723759</td>\n",
       "      <td>28.034606</td>\n",
       "      <td>2.142651</td>\n",
       "      <td>8.736073</td>\n",
       "      <td>169.685166</td>\n",
       "      <td>2.157322</td>\n",
       "      <td>92.058615</td>\n",
       "      <td>7.308772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.137000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.081960</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.452000</td>\n",
       "      <td>5.878750</td>\n",
       "      <td>45.475000</td>\n",
       "      <td>2.097050</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>281.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.085000</td>\n",
       "      <td>7.092500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.262660</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.210000</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.167500</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.100000</td>\n",
       "      <td>391.305000</td>\n",
       "      <td>11.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.717875</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.620500</td>\n",
       "      <td>94.425000</td>\n",
       "      <td>5.118000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>395.810000</td>\n",
       "      <td>17.167500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  404.000000  404.000000  404.000000  404.000000  404.000000  404.000000   \n",
       "mean     3.789989   11.568069   11.214059    0.069307    0.554524    6.284824   \n",
       "std      9.132761   24.269648    6.925462    0.254290    0.116408    0.723759   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.081960    0.000000    5.190000    0.000000    0.452000    5.878750   \n",
       "50%      0.262660    0.000000    9.690000    0.000000    0.538000    6.210000   \n",
       "75%      3.717875   12.500000   18.100000    0.000000    0.624000    6.620500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "               6           7           8           9           10          11  \\\n",
       "count  404.000000  404.000000  404.000000  404.000000  404.000000  404.000000   \n",
       "mean    69.119307    3.792258    9.660891  408.960396   18.481931  356.293020   \n",
       "std     28.034606    2.142651    8.736073  169.685166    2.157322   92.058615   \n",
       "min      2.900000    1.137000    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.475000    2.097050    4.000000  281.000000   17.400000  375.085000   \n",
       "50%     77.500000    3.167500    5.000000  330.000000   19.100000  391.305000   \n",
       "75%     94.425000    5.118000   24.000000  666.000000   20.200000  395.810000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "               12  \n",
       "count  404.000000  \n",
       "mean    12.825520  \n",
       "std      7.308772  \n",
       "min      1.920000  \n",
       "25%      7.092500  \n",
       "50%     11.560000  \n",
       "75%     17.167500  \n",
       "max     37.970000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distribution of numerical feature values across the samples\n",
    "X_train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0S3DE2_c_8j2"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 344
    },
    "id": "JEXlXchREDC6",
    "outputId": "891b630d-c9f4-4c11-9f09-dbbf883324d6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.042528</td>\n",
       "      <td>0.115681</td>\n",
       "      <td>0.394210</td>\n",
       "      <td>0.348815</td>\n",
       "      <td>0.521906</td>\n",
       "      <td>0.681970</td>\n",
       "      <td>0.241618</td>\n",
       "      <td>0.376561</td>\n",
       "      <td>0.423589</td>\n",
       "      <td>0.625738</td>\n",
       "      <td>0.897607</td>\n",
       "      <td>0.302511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.102650</td>\n",
       "      <td>0.242696</td>\n",
       "      <td>0.253866</td>\n",
       "      <td>0.239522</td>\n",
       "      <td>0.138678</td>\n",
       "      <td>0.288719</td>\n",
       "      <td>0.194973</td>\n",
       "      <td>0.379829</td>\n",
       "      <td>0.323827</td>\n",
       "      <td>0.229502</td>\n",
       "      <td>0.232131</td>\n",
       "      <td>0.202740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000850</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173387</td>\n",
       "      <td>0.137860</td>\n",
       "      <td>0.444098</td>\n",
       "      <td>0.438466</td>\n",
       "      <td>0.087361</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.179389</td>\n",
       "      <td>0.510638</td>\n",
       "      <td>0.944992</td>\n",
       "      <td>0.143481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.002881</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338343</td>\n",
       "      <td>0.314815</td>\n",
       "      <td>0.507569</td>\n",
       "      <td>0.768280</td>\n",
       "      <td>0.184767</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.272901</td>\n",
       "      <td>0.691489</td>\n",
       "      <td>0.985892</td>\n",
       "      <td>0.267406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.041717</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.646628</td>\n",
       "      <td>0.491770</td>\n",
       "      <td>0.586223</td>\n",
       "      <td>0.942585</td>\n",
       "      <td>0.362255</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.914122</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.997252</td>\n",
       "      <td>0.422954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  404.000000  404.000000  404.000000  404.000000  404.000000  404.000000   \n",
       "mean     0.042528    0.115681    0.394210    0.348815    0.521906    0.681970   \n",
       "std      0.102650    0.242696    0.253866    0.239522    0.138678    0.288719   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000850    0.000000    0.173387    0.137860    0.444098    0.438466   \n",
       "50%      0.002881    0.000000    0.338343    0.314815    0.507569    0.768280   \n",
       "75%      0.041717    0.125000    0.646628    0.491770    0.586223    0.942585   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "               6           7           8           9           10          11  \n",
       "count  404.000000  404.000000  404.000000  404.000000  404.000000  404.000000  \n",
       "mean     0.241618    0.376561    0.423589    0.625738    0.897607    0.302511  \n",
       "std      0.194973    0.379829    0.323827    0.229502    0.232131    0.202740  \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "25%      0.087361    0.130435    0.179389    0.510638    0.944992    0.143481  \n",
       "50%      0.184767    0.173913    0.272901    0.691489    0.985892    0.267406  \n",
       "75%      0.362255    1.000000    0.914122    0.808511    0.997252    0.422954  \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create column transformer\n",
    "ct = make_column_transformer(\n",
    "    (MinMaxScaler(), [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12])\n",
    ")\n",
    "\n",
    "# Normalization and data type change\n",
    "X_train = ct.fit_transform(X_train).astype('float32')\n",
    "X_test = ct.transform(X_test).astype('float32')\n",
    "y_train = y_train.astype('float32')\n",
    "y_test = y_test.astype('float32')\n",
    "\n",
    "# Distribution of X_train feature values after normalization\n",
    "pd.DataFrame(X_train).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwbgGLK9FyRG"
   },
   "source": [
    "# Model, Predict, Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0yG6aN-_RDxF",
    "outputId": "dcf22498-58a2-405e-f110-e0def71cd652"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((363, 12), (41, 12), (363,), (41,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reserve data for validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rXXjkEnchKQ0"
   },
   "source": [
    "## Creating the Model and Optimizing the Learning Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wt3qQohTiNK8"
   },
   "source": [
    "learning rate = 0.01,\n",
    "batch_size = 32,\n",
    "dense_layers = 2,\n",
    "hidden_units for Dense_1 layer= 10,\n",
    "hidden_units for Dense_2 layer = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rxuLioVJHXep",
    "outputId": "db41144b-fcda-4412-d658-e8c7b4b48129"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 363 samples, validate on 41 samples\n",
      "Epoch 1/50\n",
      "363/363 [==============================] - 2s 6ms/sample - loss: 277.1161 - mse: 277.1161 - val_loss: 124.0517 - val_mse: 124.0517\n",
      "Epoch 2/50\n",
      "363/363 [==============================] - 0s 153us/sample - loss: 79.4993 - mse: 79.4993 - val_loss: 89.2513 - val_mse: 89.2513\n",
      "Epoch 3/50\n",
      "363/363 [==============================] - 0s 146us/sample - loss: 55.9540 - mse: 55.9540 - val_loss: 71.0463 - val_mse: 71.0463\n",
      "Epoch 4/50\n",
      "363/363 [==============================] - 0s 134us/sample - loss: 48.2201 - mse: 48.2201 - val_loss: 52.0177 - val_mse: 52.0177\n",
      "Epoch 5/50\n",
      "363/363 [==============================] - 0s 122us/sample - loss: 41.8943 - mse: 41.8943 - val_loss: 47.0870 - val_mse: 47.0870\n",
      "Epoch 6/50\n",
      "363/363 [==============================] - 0s 157us/sample - loss: 37.2038 - mse: 37.2038 - val_loss: 56.4826 - val_mse: 56.4826\n",
      "Epoch 7/50\n",
      "363/363 [==============================] - 0s 237us/sample - loss: 34.8409 - mse: 34.8409 - val_loss: 49.1582 - val_mse: 49.1582\n",
      "Epoch 8/50\n",
      "363/363 [==============================] - 0s 231us/sample - loss: 30.0996 - mse: 30.0996 - val_loss: 31.6471 - val_mse: 31.6471\n",
      "Epoch 9/50\n",
      "363/363 [==============================] - 0s 226us/sample - loss: 27.0040 - mse: 27.0040 - val_loss: 24.9166 - val_mse: 24.9166\n",
      "Epoch 10/50\n",
      "363/363 [==============================] - 0s 232us/sample - loss: 26.1903 - mse: 26.1903 - val_loss: 24.0218 - val_mse: 24.0218\n",
      "Epoch 11/50\n",
      "363/363 [==============================] - 0s 226us/sample - loss: 24.8223 - mse: 24.8223 - val_loss: 24.4847 - val_mse: 24.4847\n",
      "Epoch 12/50\n",
      "363/363 [==============================] - 0s 130us/sample - loss: 24.3844 - mse: 24.3844 - val_loss: 25.1683 - val_mse: 25.1683\n",
      "Epoch 13/50\n",
      "363/363 [==============================] - 0s 127us/sample - loss: 22.6932 - mse: 22.6932 - val_loss: 28.6237 - val_mse: 28.6237\n",
      "Epoch 14/50\n",
      "363/363 [==============================] - 0s 140us/sample - loss: 23.8655 - mse: 23.8655 - val_loss: 18.2227 - val_mse: 18.2227\n",
      "Epoch 15/50\n",
      "363/363 [==============================] - 0s 157us/sample - loss: 24.3931 - mse: 24.3931 - val_loss: 24.8896 - val_mse: 24.8896\n",
      "Epoch 16/50\n",
      "363/363 [==============================] - 0s 154us/sample - loss: 22.0439 - mse: 22.0439 - val_loss: 46.5404 - val_mse: 46.5404\n",
      "Epoch 17/50\n",
      "363/363 [==============================] - 0s 141us/sample - loss: 20.9538 - mse: 20.9538 - val_loss: 31.4597 - val_mse: 31.4597\n",
      "Epoch 18/50\n",
      "363/363 [==============================] - 0s 141us/sample - loss: 22.7593 - mse: 22.7593 - val_loss: 30.9580 - val_mse: 30.9580\n",
      "Epoch 19/50\n",
      "363/363 [==============================] - 0s 157us/sample - loss: 19.1791 - mse: 19.1791 - val_loss: 18.4071 - val_mse: 18.4071\n",
      "Epoch 20/50\n",
      "363/363 [==============================] - 0s 148us/sample - loss: 23.4925 - mse: 23.4925 - val_loss: 27.9058 - val_mse: 27.9058\n",
      "Epoch 21/50\n",
      "363/363 [==============================] - 0s 157us/sample - loss: 19.6322 - mse: 19.6322 - val_loss: 21.3917 - val_mse: 21.3917\n",
      "Epoch 22/50\n",
      "363/363 [==============================] - 0s 143us/sample - loss: 19.4574 - mse: 19.4574 - val_loss: 14.0988 - val_mse: 14.0988\n",
      "Epoch 23/50\n",
      "363/363 [==============================] - 0s 141us/sample - loss: 22.3795 - mse: 22.3795 - val_loss: 22.4392 - val_mse: 22.4392\n",
      "Epoch 24/50\n",
      "363/363 [==============================] - 0s 127us/sample - loss: 21.1023 - mse: 21.1023 - val_loss: 16.3005 - val_mse: 16.3005\n",
      "Epoch 25/50\n",
      "363/363 [==============================] - 0s 135us/sample - loss: 18.0255 - mse: 18.0255 - val_loss: 23.2510 - val_mse: 23.2510\n",
      "Epoch 26/50\n",
      "363/363 [==============================] - 0s 144us/sample - loss: 20.3215 - mse: 20.3215 - val_loss: 14.3516 - val_mse: 14.3516\n",
      "Epoch 27/50\n",
      "363/363 [==============================] - 0s 135us/sample - loss: 18.6405 - mse: 18.6405 - val_loss: 14.1789 - val_mse: 14.1789\n",
      "Epoch 28/50\n",
      "363/363 [==============================] - 0s 147us/sample - loss: 17.3363 - mse: 17.3363 - val_loss: 31.4239 - val_mse: 31.4239\n",
      "Epoch 29/50\n",
      "363/363 [==============================] - 0s 143us/sample - loss: 19.3365 - mse: 19.3365 - val_loss: 12.8217 - val_mse: 12.8217\n",
      "Epoch 30/50\n",
      "363/363 [==============================] - 0s 125us/sample - loss: 19.0198 - mse: 19.0198 - val_loss: 25.0169 - val_mse: 25.0169\n",
      "Epoch 31/50\n",
      "363/363 [==============================] - 0s 146us/sample - loss: 18.8834 - mse: 18.8834 - val_loss: 14.2357 - val_mse: 14.2357\n",
      "Epoch 32/50\n",
      "363/363 [==============================] - 0s 137us/sample - loss: 17.1308 - mse: 17.1308 - val_loss: 30.5370 - val_mse: 30.5370\n",
      "Epoch 33/50\n",
      "363/363 [==============================] - 0s 137us/sample - loss: 19.3085 - mse: 19.3085 - val_loss: 12.5345 - val_mse: 12.5345\n",
      "Epoch 34/50\n",
      "363/363 [==============================] - 0s 146us/sample - loss: 20.9026 - mse: 20.9026 - val_loss: 12.8071 - val_mse: 12.8071\n",
      "Epoch 35/50\n",
      "363/363 [==============================] - 0s 140us/sample - loss: 16.8049 - mse: 16.8049 - val_loss: 18.4939 - val_mse: 18.4939\n",
      "Epoch 36/50\n",
      "363/363 [==============================] - 0s 135us/sample - loss: 17.7808 - mse: 17.7808 - val_loss: 14.1368 - val_mse: 14.1368\n",
      "Epoch 37/50\n",
      "363/363 [==============================] - 0s 147us/sample - loss: 16.8333 - mse: 16.8333 - val_loss: 13.6313 - val_mse: 13.6313\n",
      "Epoch 38/50\n",
      "363/363 [==============================] - 0s 137us/sample - loss: 18.2540 - mse: 18.2540 - val_loss: 18.2818 - val_mse: 18.2818\n",
      "Epoch 39/50\n",
      "363/363 [==============================] - 0s 129us/sample - loss: 17.0499 - mse: 17.0499 - val_loss: 16.0307 - val_mse: 16.0307\n",
      "Epoch 40/50\n",
      "363/363 [==============================] - 0s 128us/sample - loss: 15.7441 - mse: 15.7441 - val_loss: 14.1504 - val_mse: 14.1504\n",
      "Epoch 41/50\n",
      "363/363 [==============================] - 0s 146us/sample - loss: 17.1244 - mse: 17.1244 - val_loss: 12.0971 - val_mse: 12.0971\n",
      "Epoch 42/50\n",
      "363/363 [==============================] - 0s 134us/sample - loss: 17.3673 - mse: 17.3673 - val_loss: 11.5103 - val_mse: 11.5103\n",
      "Epoch 43/50\n",
      "363/363 [==============================] - 0s 134us/sample - loss: 15.9787 - mse: 15.9787 - val_loss: 11.5916 - val_mse: 11.5916\n",
      "Epoch 44/50\n",
      "363/363 [==============================] - 0s 135us/sample - loss: 15.9848 - mse: 15.9848 - val_loss: 14.8244 - val_mse: 14.8244\n",
      "Epoch 45/50\n",
      "363/363 [==============================] - 0s 135us/sample - loss: 18.5502 - mse: 18.5502 - val_loss: 14.1718 - val_mse: 14.1718\n",
      "Epoch 46/50\n",
      "363/363 [==============================] - 0s 152us/sample - loss: 16.8804 - mse: 16.8804 - val_loss: 16.4850 - val_mse: 16.4850\n",
      "Epoch 47/50\n",
      "363/363 [==============================] - 0s 137us/sample - loss: 16.4794 - mse: 16.4794 - val_loss: 35.4674 - val_mse: 35.4674\n",
      "Epoch 48/50\n",
      "363/363 [==============================] - 0s 140us/sample - loss: 16.4490 - mse: 16.4490 - val_loss: 35.3088 - val_mse: 35.3088\n",
      "Epoch 49/50\n",
      "363/363 [==============================] - 0s 133us/sample - loss: 16.9537 - mse: 16.9536 - val_loss: 13.5014 - val_mse: 13.5014\n",
      "Epoch 50/50\n",
      "363/363 [==============================] - 0s 148us/sample - loss: 15.7314 - mse: 15.7314 - val_loss: 11.1668 - val_mse: 11.1668\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Building the model\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(units=10, activation='relu', input_shape=(X_train.shape[1],), name='Dense_1'),\n",
    "  tf.keras.layers.Dense(units=100, activation='relu', name='Dense_2'),\n",
    "  tf.keras.layers.Dense(units=1, name='Prediction')\n",
    "])\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(\n",
    "    loss = tf.keras.losses.mean_squared_error,\n",
    "    optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.01),\n",
    "    metrics = ['mse']\n",
    ")\n",
    "\n",
    "# Training the model\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=32,\n",
    "    epochs=50,\n",
    "    validation_data=(X_val, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VasQEdJRe9NK"
   },
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1t-7HcflKgGV",
    "outputId": "71e123d7-73d3-4d6e-97d9-3a6aa6774076"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22.235537, 24.89756)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the mean value of training and validation data\n",
    "y_train.mean(), y_val.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4F5mom8FfACb",
    "outputId": "1577826d-50d7-47a8-ab8c-d423d52be46e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on Test data \n",
      "\n",
      "102/102 [==============================] - 0s 109us/sample - loss: 17.6822 - mse: 17.6822\n",
      "\n",
      "Model loss on test set: 17.682189156027402\n",
      "Model mean squared error on test set: 17.68\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "print(\"Evaluation on Test data \\n\")\n",
    "loss, mse = model.evaluate(X_test, y_test, batch_size=32)\n",
    "print(f\"\\nModel loss on test set: {loss}\")\n",
    "print(f\"Model mean squared error on test set: {(mse):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "1CD_HeZ1LFZ5",
    "outputId": "4caf3820-2be3-421d-9826-600baf83d452"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss curves\n",
    "pd.DataFrame(history.history).plot(figsize=(6, 4), xlabel=\"Epochs\", ylabel=\"Loss\", title='Loss Curves')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wsto_sf8fXM-"
   },
   "source": [
    "## Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TrKgnaZpfmJI",
    "outputId": "acd18217-d775-4d3a-b901-e490d8628d6f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18.295197], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# View the first prediction\n",
    "y_pred[0]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Boston_Housing_Price_Prediction_with_a_Deep_Neural_Network.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
